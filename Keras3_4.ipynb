{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras3.4.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP7M2j/w5Ae63rUndbHwMou",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moung1012/Numpy-Pandas/blob/master/Keras3_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5hrHyVDHPfF"
      },
      "source": [
        "# 영화 리뷰 분류 이진 분류 예제\n",
        "- 인터넷 영화 데이터베이스로부터 가져온 양극단의 리뷰 5만개로 이루어진 데이터셋\n",
        "- 훈련 데이터 2만 5000개와 테스트 데이터 2만 5000개로 나뉘어 있고 50%는 부정 50%는 긍정 리뷰로 구성되어 있다\n",
        "- 같은 데이터에서 훈련하고 테스트 해서는 절대 안된다\n",
        "- 중요한 것은 새로운 데이터에 대한 모델의 성능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws-A8QVCIBJ8"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "(train_data, train_labels), (test_data,test_labels) = imdb.load_data(num_words=10000)\n",
        "# nom_words = 10000 매개 변수는 훈련 데이터에서 가장 자주 나타나는 단어 1만 개만 사용하겠다는 의미\n",
        "# train_data와 test_data는 리뷰의 목록\n",
        "# 각 리뷰의 단어 인덱스의 리스트(단어 시퀀스가 인코딩 된것)\n",
        "#train_labels와 test_labels는 부정을 나타내는 0과 긍정을 나타내는 1의 리스트"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP1N9pvhIXGt"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxCAHXSQI_-A"
      },
      "source": [
        "train_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVonKbhTJDYJ"
      },
      "source": [
        "max([max(sequence)] for sequence in train_data) # 단어 1만개로 제한했기 때문에 인덱스는 9,999"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z13XgwvIJQYJ"
      },
      "source": [
        "word_index = imdb.get_word_index() # word_index는 단어와 정수 인덱스를 매핑한 딕셔너리\n",
        "revers_word_index= dict(\n",
        "    [(value, key) for (key, value) in word_index.items()]) # 정수 인덱스와 단어를 매핑하도록 뒤집는다\n",
        "decoded_review = ' '.join(\n",
        "    [reverse_word_index.get(i - 3,'?')for i in train_data[0]]) # 리뷰를 디코딩한다 0,1,2는 '패딩','문서 시작','사전에 없음'을 위한 인덱스이므로 3을 뺀다"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1-ONywwKqzO"
      },
      "source": [
        "### 데이터 준비  \n",
        "리스트를 텐서로 바꾸는 두가지 방법  \n",
        "- 같은 길이가 되도록 리스트에 패딩을 추가하고 (samples, sequence_length)크기의 정수 텐서로 변환 그 다음 정수 텐서를 다룰 수 있는 층을 신경망의 첫 번째 층으로 사용  \n",
        "- 리시트를 원-핫 인코딩(one-hot incoding)하여 0과 1의 벡터로 변환한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7VHexGsMGAp"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    # 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듭니다\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.  # results[i]에서 특정 인덱스의 위치를 1로 만듭니다\n",
        "    return results\n",
        "\n",
        "# 훈련 데이터를 벡터로 변환합니다\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# 테스트 데이터를 벡터로 변환합니다\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6J3dqt6MhSI"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3fUEGppM08o"
      },
      "source": [
        "# 레이블을 벡터로 바꿉니다\n",
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkco3uShM9K1"
      },
      "source": [
        "### 신경망 모델 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE4a-CYhNFMS"
      },
      "source": [
        "Dense 층을 쌓을 때 두가지 중요한 구조상의 결정이 필요하다  \n",
        "- 얼마나 많은 층을 사용할 것인가\n",
        "- 각 층에 얼마나 많은 은닉 유닛을 둘 것인가  \n",
        "현재 모델의 구조  \n",
        "- 16개의 은닉 유닛을 가진 2개의 은닉 층\n",
        "- 현재 리뷰의 감정을 스칼라 값의 예측으로 출력하는 세 번째 층"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAVmVWkPdNmd"
      },
      "source": [
        "다음이 이 신경망의 모습입니다:\n",
        "\n",
        "![3-layer network](https://s3.amazonaws.com/book.keras.io/img/ch3/3_layer_network.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNfI1aHldyHY"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "# 중간의 은닉층은 활성화 함수 relu를 사용하고 마지막 층은 확률을 출력하기 위해 시그모이드 활성화 함수 사용"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnmaNxDYeCE5"
      },
      "source": [
        "---\n",
        "마지막으로 손실 함수와 옵티마이저를 선택  \n",
        "- 이진 분류 문제이고 신경망의 출력이 확률이기 때문에 binary_crossentropy 손실이 적합\n",
        "- 확률을 출력하는 모델을 사용할 때는 크로스엔트로피가 최선의 선택\n",
        "- 크로스엔트로피는 정보 이론 뷴야에서 온 개념으로 확률 분포 간의 차이를 측정한다(여기서는 원본 분포와 예측 분포 사이를 측정)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K1EWqzZe0i_"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "#rmsprop 옵티마이저와 binary_crossentropy 손실 함수로 모델을 설정하는 단계"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvrLEuxee21W"
      },
      "source": [
        "rmsprop, binary_crossentropy, accuracy가 포함되어 있기 때문에 옵티마이저, 손실 함수, 측정 지표를 문자열로 지정하는 것이 가능  \n",
        "- 옵티마이저의 매개변수를 바꾸거나 자신만의 손실 함수, 측정 함수를 전달해야 할 경우 옵티마이저 파이썬 클래스를 사용해 직접 만들어 옵티마이저 매개변수에 전달"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5uqXyDIfOQd"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qIkjDvPfQFp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}